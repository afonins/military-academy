import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle, Circle, FancyBboxPatch
from matplotlib.collections import LineCollection
import time
from environment import FixedPatrolEnv
from agent import PatrolAgent


class PatrolVisualizer:
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–∞—Ç—Ä—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å –∞–Ω–∏–º–∞—Ü–∏–µ–π."""
    
    def __init__(self, env: FixedPatrolEnv, agent: PatrolAgent):
        self.env = env
        self.agent = agent
        self.fig = None
        self.axes = None
        self.heatmap_im = None
        
    def setup_plot(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤."""
        self.fig, self.axes = plt.subplots(1, 2, figsize=(14, 6))
        
        # –õ–µ–≤–∞—è –ø–∞–Ω–µ–ª—å - –∫–∞—Ä—Ç–∞ –ø–∞—Ç—Ä—É–ª—è
        self.ax_map = self.axes[0]
        self.ax_map.set_xlim(-0.5, self.env.size - 0.5)
        self.ax_map.set_ylim(-0.5, self.env.size - 0.5)
        self.ax_map.set_aspect('equal')
        self.ax_map.invert_yaxis()
        self.ax_map.set_xticks(range(self.env.size))
        self.ax_map.set_yticks(range(self.env.size))
        self.ax_map.grid(True, alpha=0.3)
        self.ax_map.set_title('–ö–∞—Ä—Ç–∞ –ø–∞—Ç—Ä—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è', fontsize=14, fontweight='bold')
        
        # –ü—Ä–∞–≤–∞—è –ø–∞–Ω–µ–ª—å - —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞
        self.ax_heatmap = self.axes[1]
        self.heatmap_im = self.ax_heatmap.imshow(
            np.zeros((self.env.size, self.env.size)),
            cmap='YlOrRd',
            vmin=0,
            vmax=5,
            extent=[-0.5, self.env.size - 0.5, self.env.size - 0.5, -0.5]
        )
        plt.colorbar(self.heatmap_im, ax=self.ax_heatmap, label='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–µ—â–µ–Ω–∏–π')
        self.ax_heatmap.set_title('–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –ø–æ—Å–µ—â–µ–Ω–∏–π', fontsize=14, fontweight='bold')
        self.ax_heatmap.set_xticks(range(self.env.size))
        self.ax_heatmap.set_yticks(range(self.env.size))
        
        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (—Å—Ç–µ–Ω—ã, –∑–æ–Ω—ã —Ä–∏—Å–∫–∞)
        self._draw_static_elements()
        
        plt.tight_layout()
        
    def _draw_static_elements(self):
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–∞—Ä—Ç—ã."""
        # –°—Ç–µ–Ω—ã
        for (y, x) in self.env.walls:
            rect = Rectangle((x - 0.5, y - 0.5), 1, 1, 
                           facecolor='#2c3e50', edgecolor='black', linewidth=2)
            self.ax_map.add_patch(rect)
        
        # –ó–æ–Ω—ã —Ä–∏—Å–∫–∞ (–ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ)
        for (y, x) in self.env.risk_zones:
            circle = Circle((x, y), 0.6, facecolor='red', alpha=0.15, edgecolor='red', linewidth=1)
            self.ax_map.add_patch(circle)
    
    def update(self, path, current_pos, targets, step, total_reward, stats):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏."""
        # –û—á–∏—Å—Ç–∫–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        for artist in list(self.ax_map.patches) + list(self.ax_map.collections) + list(self.ax_map.texts):
            if isinstance(artist, (Circle, Rectangle)) and artist.get_facecolor() not in [(0.1725, 0.2431, 0.3137, 1.0), (1.0, 0.0, 0.0, 0.15)]:
                artist.remove()
            elif isinstance(artist, plt.Line2D):
                artist.remove()
        
        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –ø—É—Ç–∏
        if len(path) > 1:
            ys, xs = zip(*path)
            self.ax_map.plot(xs, ys, 'b-', linewidth=2, alpha=0.5, zorder=1)
        
        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞
        agent_rect = FancyBboxPatch(
            (current_pos[1] - 0.35, current_pos[0] - 0.35), 0.7, 0.7,
            boxstyle="round,pad=0.02", 
            facecolor='#3498db', edgecolor='#2980b9', linewidth=2, zorder=5
        )
        self.ax_map.add_patch(agent_rect)
        
        # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∑–≥–ª—è–¥–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—è)
        if len(path) >= 2:
            dy = current_pos[0] - path[-2][0]
            dx = current_pos[1] - path[-2][1]
            self.ax_map.arrow(
                current_pos[1], current_pos[0], dx * 0.3, dy * 0.3,
                head_width=0.2, head_length=0.15, fc='#2980b9', ec='#2980b9', zorder=6
            )
        
        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –≤—Ä–∞–≥–æ–≤
        for t in targets:
            enemy_circle = Circle(
                (t[1], t[0]), 0.35,
                facecolor='#e74c3c', edgecolor='#c0392b', linewidth=2, zorder=4
            )
            self.ax_map.add_patch(enemy_circle)
            # –¢–∞–π–º–µ—Ä –∂–∏–∑–Ω–∏
            self.ax_map.text(
                t[1], t[0], str(t[2]),
                ha='center', va='center', fontsize=8, color='white', fontweight='bold', zorder=5
            )
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        self.ax_map.set_title(
            f'–®–∞–≥: {step} | –ù–∞–≥—Ä–∞–¥–∞: {total_reward:.1f} | '
            f'–ü–æ–π–º–∞–Ω–æ: {stats["caught"]} | –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats["missed"]}',
            fontsize=12
        )
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–µ–ø–ª–æ–≤–æ–π –∫–∞—Ä—Ç—ã
        self.heatmap_im.set_array(self.env.visit_count)
        max_visits = np.max(self.env.visit_count) + 1
        self.heatmap_im.set_clim(0, max_visits)
        self.ax_heatmap.set_title(
            f'–ü–æ—Å–µ—â–µ–Ω–æ: {stats["unique_cells"]}/{self.env.size * self.env.size - len(self.env.walls)} –∫–ª–µ—Ç–æ–∫ | '
            f'–ü–æ–∫—Ä—ã—Ç–∏–µ: {stats["coverage"]*100:.1f}%',
            fontsize=12
        )
        
        self.fig.canvas.draw()
        self.fig.canvas.flush_events()


def run_demo(agent=None, episodes=3, delay=0.3, visualize=True):
    """
    –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞.
    
    Args:
        agent: –û–±—É—á–µ–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç (–µ—Å–ª–∏ None, –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è –∏–∑ —Ñ–∞–π–ª–∞)
        episodes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ–º–æ-—ç–ø–∏–∑–æ–¥–æ–≤
        delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏ (—Å–µ–∫)
        visualize: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    """
    # –°–æ–∑–¥–∞–µ–º —Å—Ä–µ–¥—É –∏ –∞–≥–µ–Ω—Ç–∞
    env = FixedPatrolEnv(size=10, max_steps=200)
    if agent is None:
        agent = PatrolAgent(map_size=10, use_dueling=True, load_model=True)
    
    print("=" * 60)
    print("üé¨ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –û–ë–£–ß–ï–ù–ù–û–ì–û –ê–ì–ï–ù–¢–ê")
    print("=" * 60)
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤: {episodes}")
    print(f"Epsilon (exploration): {agent.epsilon:.4f}")
    print("=" * 60)
    
    if visualize:
        plt.ion()
        visualizer = PatrolVisualizer(env, agent)
        visualizer.setup_plot()
    
    all_stats = []
    
    for ep in range(episodes):
        state = env.reset()
        total_reward = 0.0
        path = [tuple(env.pos)]
        
        print(f"\nüéÆ –≠–ø–∏–∑–æ–¥ {ep + 1}/{episodes}")
        
        for step in range(env.max_steps):
            # –í—ã–±–æ—Ä –¥–µ–π—Å—Ç–≤–∏—è (–±–µ–∑ exploration)
            action = agent.select_action(state, training=False)
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            next_state, reward, done, info = env.step(action)
            total_reward += reward
            state = next_state
            path.append(tuple(env.pos))
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            if visualize and step % 2 == 0:
                stats = env.get_stats()
                visualizer.update(path, env.pos, env.targets, step, total_reward, stats)
                plt.pause(delay)
            
            if done:
                break
        
        # –ò—Ç–æ–≥–∏ —ç–ø–∏–∑–æ–¥–∞
        stats = env.get_stats()
        all_stats.append(stats)
        
        print(f"   ‚úÖ –ù–∞–≥—Ä–∞–¥–∞: {total_reward:.2f}")
        print(f"   ‚úÖ –ü–æ–∫—Ä—ã—Ç–∏–µ: {stats['coverage']*100:.1f}%")
        print(f"   ‚úÖ –ü–æ–π–º–∞–Ω–æ –≤—Ä–∞–≥–æ–≤: {stats['caught']}")
        print(f"   ‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–æ –≤—Ä–∞–≥–æ–≤: {stats['missed']}")
        print(f"   ‚úÖ –®–∞–≥–æ–≤: {stats['steps']}")
        
        if visualize:
            plt.pause(1.0)
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 60)
    avg_coverage = np.mean([s['coverage'] for s in all_stats])
    avg_caught = np.mean([s['caught'] for s in all_stats])
    avg_missed = np.mean([s['missed'] for s in all_stats])
    avg_steps = np.mean([s['steps'] for s in all_stats])
    
    print(f"–°—Ä–µ–¥–Ω–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ: {avg_coverage*100:.1f}%")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –ø–æ–π–º–∞–Ω–æ: {avg_caught:.1f}")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ: {avg_missed:.1f}")
    print(f"–°—Ä–µ–¥–Ω–µ–µ —à–∞–≥–æ–≤: {avg_steps:.1f}")
    print("=" * 60)
    
    if visualize:
        plt.ioff()
        plt.show()
    
    return all_stats


def run_text_demo(agent=None, episodes=3):
    """–¢–µ–∫—Å—Ç–æ–≤–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è (–±–µ–∑ –≥—Ä–∞—Ñ–∏–∫–∏)."""
    env = FixedPatrolEnv(size=10, max_steps=200)
    if agent is None:
        agent = PatrolAgent(map_size=10, use_dueling=True, load_model=True)
    
    print("=" * 60)
    print("üé¨ –¢–ï–ö–°–¢–û–í–ê–Ø –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø")
    print("=" * 60)
    
    for ep in range(episodes):
        state = env.reset()
        total_reward = 0.0
        
        print(f"\nüéÆ –≠–ø–∏–∑–æ–¥ {ep + 1}/{episodes}")
        
        for step in range(100):
            env.render_text()
            time.sleep(0.3)
            
            action = agent.select_action(state, training=False)
            next_state, reward, done, info = env.step(action)
            total_reward += reward
            state = next_state
            
            if done:
                break
        
        stats = env.get_stats()
        print(f"\n‚úÖ –ù–∞–≥—Ä–∞–¥–∞: {total_reward:.2f}, –ü–æ–∫—Ä—ã—Ç–∏–µ: {stats['coverage']*100:.1f}%")
        time.sleep(1)


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –≤–∏–∑—É–∞–ª—å–Ω–æ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    run_demo(episodes=3, delay=0.2, visualize=True)
    
    # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π:
    # run_text_demo(episodes=3)
